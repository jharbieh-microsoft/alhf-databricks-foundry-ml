
# ğŸš¦ TL;DR: Azure AI Foundry Blueprint to support Agent Learning from Human Feedback (ALHF)?
Here is a clean, practical **blueprint** you can use to implement *Databricksâ€‘style Agent Learning from Human Feedback (ALHF)* patterns using **Azure AI Foundry**

# â­ Blueprint: â€œHumanâ€‘Feedbackâ€‘Driven Agent Improvement Loopâ€

### (Azure AI Foundry Ã— Databricks ALHF concepts)

This blueprint blends:

*   **Databricks ALHF** â€” agents learn from lightweight naturalâ€‘language feedback (answer quality, adherence, completeness). [\[databricks.com\]](https://www.databricks.com/blog/agent-learning-human-feedback-alhf-databricks-knowledge-assistant-case-study)
*   **Azure AI Foundry** â€” rich evaluation stack: human evaluation templates, synthetic evaluators, AI Red Teaming, observability, workflowâ€‘level evaluators, and fineâ€‘tuning hooks.
*   **Your realâ€‘world Foundry discussions** â€” evaluation blade, new evaluators announced at Ignite.

The result is a *closed-loop agent improvement architecture* you can deploy today.

***

# 1ï¸âƒ£ Establish the Agent + Instrumentation

## **1. Define the agent**

In Azure AI Foundry:

*   Select your base model (GPTâ€‘4o, GPTâ€‘4 Turbo, Phiâ€‘3, etc.).
*   Apply initial customization (system message, task boundaries, optional fineâ€‘tuning dataset).
*   Configure tools: Search, SharePoint, APIs, Functions, etc. (if needed).

## **2. Turn on Observability + Logging**

You need:

*   **Application Insights**
*   **Foundry Agent Observability** (traces, spans, tool calls, memory, and chain logs)
*   **Evaluation Blade** access

This gives you agent message logs and workflow traces â€” required for both synthetic evaluators and human feedback loops. 

# 2ï¸âƒ£ Implement ALHFâ€‘Style Human Feedback Capture

Azure AI Foundry provides a native **Human Evaluation** system that parallels Databricks ALHF.    [\[learn.microsoft.com\]](https://learn.microsoft.com/en-us/azure/ai-foundry/observability/how-to/human-evaluation?view=foundry)

## **1. Create Human Evaluation Templates**

Define lightweight prompts reviewers use to grade agent responses:

Example questions:

*   â€œDid the agent answer the question correctly?â€ (thumbs up/down)
*   â€œHow complete was the answer?â€ (slider)
*   â€œDid the agent stay grounded in retrieved context?â€ (multiple choice)
*   â€œWhat should the agent have done instead?â€ (free-text)

Supported question formats:  
âœ” Thumbs  
âœ” Multiple choice  
âœ” Sliders  
âœ” Freeâ€‘form text

## **2. Enable Feedback Capture During Agent Preview**

Reviewers see each turn â†’ provide feedback right inside the portal â†’ results logged to evaluation tables.

## **3. Download and Store Human Feedback**

Use:

*   Export via Foundry portal
*   Pipe to custom storage for training datasets
*   Attach feedback back to trace IDs (mirrors Databricks "assessment objects" in MLflow)    [\[learn.microsoft.com\]](https://learn.microsoft.com/en-us/azure/databricks/mlflow3/genai/human-feedback/)

***

# 3ï¸âƒ£ Add Synthetic + Automated Evaluation (Optional but Recommended)

Azure provides a rich evaluator suite:    [\[learn.microsoft.com\]](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk?view=foundry-classic)

### **Builtâ€‘in Evaluators**

*   Intent resolution
*   Tool-call accuracy
*   Task adherence
*   Latency
*   Safety & content quality
*   Workflow-step analysis
*   Groundedness

### **Risk + Redâ€‘Teaming**

AI Red Teaming Agent (PyRIT integrated):

*   Adversarial probe
*   Attack Success Rate
*   Risk categories
*   Scorecards 

This helps ensure the agent improves safely, not just â€œoptimizing for pleasing humans.â€

***

# 4ï¸âƒ£ Combine Feedback Sources Into a Unified Training Dataset

This is the â€œfusionâ€ step that mirrors Databricks ALHF:

*   Minimal feedback â†’ large agent improvement    [\[databricks.com\]](https://www.databricks.com/blog/agent-learning-human-feedback-alhf-databricks-knowledge-assistant-case-study)

Construct a dataset combining:

1.  **Human Evaluation results** (qualitative)
2.  **Synthetic Evaluator results** (systematic)
3.  **Redâ€‘teaming logs**
4.  **Traces + Expected outputs** (for groundedness)

### **Target Columns:**

-â€¯*Input*  
-â€¯*Agent output*  
-â€¯*Human expected output* (if provided)  
-â€¯*Feedback scores*  
-â€¯*Error classification*  
-â€¯*Context retrieval artifacts*

You now have a clean supervised dataset ready to improve your agent.

***

# 5ï¸âƒ£ Apply Improvements: Fineâ€‘Tuning, Prompt Shaping, or Policy Updates

### Option A â€” **Fineâ€‘tune** the model

You can create:

*   Instructionâ€‘tuned datasets
*   â€œCorrection pairsâ€ (Input â†’ Corrected Output)
*   Multi-turn threads capturing correct workflows

### Option B â€” **Prompt/Policy Optimization**

Feed learnings into:

*   System message clarifications
*   Role instructions
*   Toolâ€‘use constraints
*   Safety policies
*   Guardrail and memory configurations

### Option C â€” **Task / Workflow-Level Improvements**

If agent fails in the chain logic:

*   Adjust workflow state machine
*   Improve tool preconditions
*   Add new evaluation checkpoints
*   Restructure multiâ€‘agent orchestration

***

# 6ï¸âƒ£ Continuous Evaluation Loop (Closedâ€‘Loop Learning)

### After redeploying improved agent:

1.  Run **synthetic evaluators** again â†’ see if scores improved.
2.  Re-enable **human evaluation** templates â†’ collect new scores.
3.  Review **Application Insights traces** â†’ identify regressions.
4.  Repeat fineâ€‘tune / prompt updates until:
    *   Intent resolution > target threshold
    *   Groundedness score stable
    *   Task adherence consistent
    *   Safety violations minimal

This is fully aligned with Microsoft guidance:

*   â€œSystem Evaluation + Process Evaluationâ€ for workflow agents.    [\[learn.microsoft.com\]](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk?view=foundry-classic)

***

# 7ï¸âƒ£ (Optional) Multiâ€‘Agent Extension

With Foundryâ€™s multi-agent workflows

*   Add evaluators per agent role (planner, solver, retriever, verifier)
*   Capture inter-agent handoff quality
*   Produce crossâ€‘agent scoring (â€œworkflow consistencyâ€)

***

# ğŸ§© Visual Summary of the Blueprint (Text Version)

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           1. Build Agent in Foundry       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚    2. Enable Observability       â”‚
           â”‚ (Traces, Spans, Tool Calls, AI)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   3. Collect Human Feedback (ALHF)     â”‚
         â”‚  - Human Eval Templates                â”‚
         â”‚  - Reviewer Scoring in Portal          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   4. Automated + Synthetic Evaluators â”‚
           â”‚ - Intent, Tool, Safety, Red-teaming   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      5. Build Unified Training Data     â”‚
         â”‚ (Feedback + Expected Outputs + Traces) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚       6. Improve Model/Policies       â”‚
           â”‚  Fine-tune OR Prompt Tuning OR Logic  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     7. Continuous Evaluation Loop       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

***

# ğŸ”¥ Deliverable You Can Hand to Customers

This blueprint works for:

*   **PIT â†’ POC** acceleration
*   **Agent governance frameworks**
*   **Evaluation strategy workshops**
*   **Pilot â†’ Production uplift**
*   **Azure AI Foundry Agent Service adoption**
*   **ALHF-style iterative learning**
